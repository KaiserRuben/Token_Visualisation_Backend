{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inseq Feature Attribution API Visualization\n",
    "\n",
    "This notebook demonstrates how to interact with the Inseq Feature Attribution API and visualize the results. The helper functions for interacting with the API can be found in `api_client.py`."
   ],
   "id": "caddb49947874c43"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:18:40.717584Z",
     "start_time": "2025-03-12T17:18:40.714838Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Import our helper functions\n",
    "from api_client import (\n",
    "    # API interaction functions\n",
    "    submit_attribution_job,\n",
    "    check_job_status,\n",
    "    get_job_results,\n",
    "    wait_for_job_completion,\n",
    "    \n",
    "    # Data processing functions\n",
    "    create_attribution_dataframe,\n",
    "    find_important_tokens,\n",
    "    \n",
    "    # Visualization functions\n",
    "    visualize_attributions,\n",
    "    plot_step_scores,\n",
    "    plot_multiple_step_scores,\n",
    "    visualize_attribution_flow,\n",
    "    \n",
    "    # Complete workflows\n",
    "    run_attribution_workflow,\n",
    "    compare_attribution_methods,\n",
    "    \n",
    "    # Reference data\n",
    "    ATTRIBUTION_METHODS,\n",
    "    STEP_SCORE_FUNCTIONS,\n",
    "    RECOMMENDED_MODELS\n",
    ")"
   ],
   "id": "bdc8f44ecfdbacf1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Configuration\n",
    "\n",
    "Set the base URL for the API. Update this if your API is running on a different host or port."
   ],
   "id": "4fccda70c5290c11"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:18:40.723990Z",
     "start_time": "2025-03-12T17:18:40.721844Z"
    }
   },
   "source": [
    "# Configure the API base URL\n",
    "API_BASE_URL = \"http://localhost:8000\""
   ],
   "id": "46dae2762b6d64f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Attribution Methods and Step Scores\n",
    "\n",
    "The API supports various attribution methods and step score functions. Let's explore the available options."
   ],
   "id": "539677eb6b4f0894"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:18:40.737177Z",
     "start_time": "2025-03-12T17:18:40.731515Z"
    }
   },
   "source": [
    "# Display available attribution methods\n",
    "methods_df = pd.DataFrame.from_dict(ATTRIBUTION_METHODS, orient='index')\n",
    "print(\"Available Attribution Methods:\")\n",
    "display(methods_df)"
   ],
   "id": "8113c0062932fe0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Attribution Methods:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                      description complexity  \\\n",
       "input_x_gradient                     Input multiplied by gradient        Low   \n",
       "saliency                              Simple gradient attribution        Low   \n",
       "integrated_gradients                  Integrated Gradients method     Medium   \n",
       "deep_lift                                         DeepLIFT method     Medium   \n",
       "gradient_shap                                 GradientSHAP method     Medium   \n",
       "layer_integrated_gradients             Layer Integrated Gradients     Medium   \n",
       "layer_gradient_x_activation           Layer Gradient × Activation     Medium   \n",
       "layer_deep_lift                                    Layer DeepLIFT     Medium   \n",
       "attention                                       Attention weights        Low   \n",
       "occlusion                             Occlusion-based attribution     Medium   \n",
       "lime                                       LIME-based attribution       High   \n",
       "value_zeroing                                Value Zeroing method     Medium   \n",
       "reagent                           Recursive attribution generator       High   \n",
       "discretized_integrated_gradients                   Discretized IG     Medium   \n",
       "sequential_integrated_gradients                     Sequential IG     Medium   \n",
       "\n",
       "                                   speed special_params  \n",
       "input_x_gradient                    Fast           None  \n",
       "saliency                            Fast           None  \n",
       "integrated_gradients              Medium        n_steps  \n",
       "deep_lift                         Medium        n_steps  \n",
       "gradient_shap                     Medium        n_steps  \n",
       "layer_integrated_gradients        Medium        n_steps  \n",
       "layer_gradient_x_activation       Medium           None  \n",
       "layer_deep_lift                   Medium        n_steps  \n",
       "attention                           Fast           None  \n",
       "occlusion                           Slow           None  \n",
       "lime                                Slow           None  \n",
       "value_zeroing                     Medium           None  \n",
       "reagent                             Slow           None  \n",
       "discretized_integrated_gradients  Medium        n_steps  \n",
       "sequential_integrated_gradients   Medium        n_steps  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>complexity</th>\n",
       "      <th>speed</th>\n",
       "      <th>special_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_x_gradient</th>\n",
       "      <td>Input multiplied by gradient</td>\n",
       "      <td>Low</td>\n",
       "      <td>Fast</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saliency</th>\n",
       "      <td>Simple gradient attribution</td>\n",
       "      <td>Low</td>\n",
       "      <td>Fast</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>integrated_gradients</th>\n",
       "      <td>Integrated Gradients method</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>n_steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep_lift</th>\n",
       "      <td>DeepLIFT method</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>n_steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_shap</th>\n",
       "      <td>GradientSHAP method</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>n_steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_integrated_gradients</th>\n",
       "      <td>Layer Integrated Gradients</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>n_steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_gradient_x_activation</th>\n",
       "      <td>Layer Gradient × Activation</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_deep_lift</th>\n",
       "      <td>Layer DeepLIFT</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>n_steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attention</th>\n",
       "      <td>Attention weights</td>\n",
       "      <td>Low</td>\n",
       "      <td>Fast</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occlusion</th>\n",
       "      <td>Occlusion-based attribution</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Slow</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lime</th>\n",
       "      <td>LIME-based attribution</td>\n",
       "      <td>High</td>\n",
       "      <td>Slow</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value_zeroing</th>\n",
       "      <td>Value Zeroing method</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reagent</th>\n",
       "      <td>Recursive attribution generator</td>\n",
       "      <td>High</td>\n",
       "      <td>Slow</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discretized_integrated_gradients</th>\n",
       "      <td>Discretized IG</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>n_steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequential_integrated_gradients</th>\n",
       "      <td>Sequential IG</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>n_steps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:18:40.752104Z",
     "start_time": "2025-03-12T17:18:40.747503Z"
    }
   },
   "source": [
    "# Display available step score functions\n",
    "scores_df = pd.DataFrame.from_dict(STEP_SCORE_FUNCTIONS, orient='index', columns=['Description'])\n",
    "print(\"Available Step Score Functions:\")\n",
    "display(scores_df)"
   ],
   "id": "c34fd5e76abadcdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Step Score Functions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                            Description\n",
       "logit                                         Logit of the target token\n",
       "probability                             Probability of the target token\n",
       "entropy                                  Entropy of output distribution\n",
       "crossentropy                    Cross entropy between target and logits\n",
       "perplexity                             Perplexity of target from logits\n",
       "contrast_logits         Logit of a generation given contrastive context\n",
       "contrast_prob                     Probability given contrastive context\n",
       "contrast_logits_diff  Difference between logits with contrastive inputs\n",
       "contrast_prob_diff    Difference between probabilities with contrast...\n",
       "pcxmi                    Pointwise conditional cross-mutual information\n",
       "kl_divergence                       KL divergence between distributions\n",
       "in_context_pvi                In-context pointwise V-usable information\n",
       "mc_dropout_prob_avg             Monte Carlo dropout probability average\n",
       "top_p_size            Number of tokens with cumulative probability a..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logit</th>\n",
       "      <td>Logit of the target token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probability</th>\n",
       "      <td>Probability of the target token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>Entropy of output distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crossentropy</th>\n",
       "      <td>Cross entropy between target and logits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>Perplexity of target from logits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast_logits</th>\n",
       "      <td>Logit of a generation given contrastive context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast_prob</th>\n",
       "      <td>Probability given contrastive context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast_logits_diff</th>\n",
       "      <td>Difference between logits with contrastive inputs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast_prob_diff</th>\n",
       "      <td>Difference between probabilities with contrast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcxmi</th>\n",
       "      <td>Pointwise conditional cross-mutual information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kl_divergence</th>\n",
       "      <td>KL divergence between distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_context_pvi</th>\n",
       "      <td>In-context pointwise V-usable information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mc_dropout_prob_avg</th>\n",
       "      <td>Monte Carlo dropout probability average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_p_size</th>\n",
       "      <td>Number of tokens with cumulative probability a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:18:40.798935Z",
     "start_time": "2025-03-12T17:18:40.794042Z"
    }
   },
   "source": [
    "# Display recommended models\n",
    "models_df = pd.DataFrame.from_dict(RECOMMENDED_MODELS, orient='index', columns=['Description'])\n",
    "print(\"Recommended Models:\")\n",
    "display(models_df)"
   ],
   "id": "dc8d0fa5db09ac0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Models:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                     Description\n",
       "distilgpt2            Lightweight GPT-2 model, works well on CPU\n",
       "gpt2                                        Standard GPT-2 model\n",
       "facebook/opt-125m                                Small OPT model\n",
       "google/flan-t5-small            Small T5 model (encoder-decoder)"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distilgpt2</th>\n",
       "      <td>Lightweight GPT-2 model, works well on CPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>Standard GPT-2 model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/opt-125m</th>\n",
       "      <td>Small OPT model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/flan-t5-small</th>\n",
       "      <td>Small T5 model (encoder-decoder)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Attribution Workflow\n",
    "\n",
    "This example demonstrates a complete attribution workflow, from submitting a job to visualizing the results."
   ],
   "id": "a5745e592e38acf8"
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-12T17:18:40.861069Z"
    }
   },
   "source": [
    "# Run a simple attribution workflow\n",
    "simple_results = run_attribution_workflow(\n",
    "    input_text=\"Hello Ladies and \",\n",
    "    model=\"distilgpt2\",  # Using a smaller model for faster processing\n",
    "    method=\"input_x_gradient\",\n",
    "    step_scores=[\"probability\", \"logit\"],\n",
    "    api_base_url=API_BASE_URL\n",
    ")"
   ],
   "id": "dffe7d17ef6c2b1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Comparing Different Attribution Methods\n",
    "\n",
    "This example shows how to compare different attribution methods on the same input text."
   ],
   "id": "f3e80024d9a079ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare different attribution methods\n",
    "comparison_results = compare_attribution_methods(\n",
    "    input_text=\"Feature attribution helps explain model predictions.\",\n",
    "    methods=[\"input_x_gradient\", \"saliency\", \"attention\"],  # Choose methods to compare\n",
    "    model=\"distilgpt2\",\n",
    "    api_base_url=API_BASE_URL\n",
    ")"
   ],
   "outputs": [],
   "id": "889c687f44e43b37"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Advanced Visualization - Attribution Flow\n",
    "\n",
    "This visualization shows how attribution flows from source to target tokens using a network graph."
   ],
   "id": "13a2735dcd1a766f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Only run this if you've already run one of the examples above\n",
    "if 'simple_results' in locals():\n",
    "    print(\"Creating attribution flow visualization...\")\n",
    "    G = visualize_attribution_flow(simple_results[\"df_attribution\"], threshold=0.1)\n",
    "else:\n",
    "    print(\"Please run Example 1 first to generate attribution results.\")"
   ],
   "outputs": [],
   "id": "51fa264677dd71fd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Custom Attribution Job\n",
    "\n",
    "This example shows how to execute each step of the attribution process individually, which gives you more control over the workflow."
   ],
   "id": "804a732a3a8ddab6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define the input text and parameters\n",
    "input_text = \"Natural language processing has advanced significantly with transformers.\"\n",
    "model = \"distilgpt2\"\n",
    "method = \"integrated_gradients\"\n",
    "\n",
    "# Step 1: Submit the attribution job\n",
    "print(f\"Submitting attribution job with method: {method}\")\n",
    "job_id = submit_attribution_job(\n",
    "    input_text=input_text,\n",
    "    model=model,\n",
    "    method=method,\n",
    "    step_scores=[\"probability\", \"entropy\", \"perplexity\"],\n",
    "    n_steps=20,  # Important for integrated_gradients\n",
    "    force_cpu=True,\n",
    "    api_base_url=API_BASE_URL\n",
    ")\n",
    "print(f\"Job submitted with ID: {job_id}\")\n",
    "\n",
    "# Step 2: Wait for the job to complete\n",
    "print(\"Waiting for job to complete...\")\n",
    "job_status = wait_for_job_completion(job_id, api_base_url=API_BASE_URL)\n",
    "print(f\"Job completed with status: {job_status['status']}\")\n",
    "\n",
    "# Step 3: Get the results\n",
    "results = get_job_results(job_id, api_base_url=API_BASE_URL)\n",
    "\n",
    "# Step 4: Create a DataFrame of attribution scores\n",
    "df_attribution = create_attribution_dataframe(results)\n",
    "print(\"\\nAttribution Scores DataFrame:\")\n",
    "display(df_attribution)\n",
    "\n",
    "# Step 5: Visualize the attribution scores\n",
    "print(\"\\nVisualizing attribution scores...\")\n",
    "visualize_attributions(df_attribution)\n",
    "\n",
    "# Step 6: Plot the step scores\n",
    "print(\"\\nPlotting step scores...\")\n",
    "df_step_scores = plot_step_scores(results)\n",
    "\n",
    "# Step 7: Plot each step score separately for clarity\n",
    "if df_step_scores is not None and len(df_step_scores.columns) > 1:\n",
    "    print(\"\\nPlotting individual step scores...\")\n",
    "    plot_multiple_step_scores(df_step_scores)\n",
    "\n",
    "# Step 8: Find the most important source token for each target token\n",
    "df_important = find_important_tokens(df_attribution)\n",
    "print(\"\\nMost important source token for each target token:\")\n",
    "display(df_important)"
   ],
   "outputs": [],
   "id": "2c95b9805996513f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Working with Step Scores\n",
    "\n",
    "This example focuses specifically on using and analyzing different step scores."
   ],
   "id": "f64aebe67cefd84"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_step_scores(input_text=\"Explain how feature attribution works.\"):\n",
    "    \"\"\"Run attribution with multiple step scores and analyze them.\"\"\"\n",
    "    # Submit a job with multiple step scores\n",
    "    job_id = submit_attribution_job(\n",
    "        input_text=input_text,\n",
    "        model=\"distilgpt2\",\n",
    "        method=\"input_x_gradient\",\n",
    "        step_scores=[\"probability\", \"logit\", \"entropy\", \"perplexity\"],\n",
    "        force_cpu=True,\n",
    "        api_base_url=API_BASE_URL\n",
    "    )\n",
    "    \n",
    "    print(f\"Job submitted with ID: {job_id}\")\n",
    "    job_status = wait_for_job_completion(job_id, api_base_url=API_BASE_URL)\n",
    "    print(f\"Job completed with status: {job_status['status']}\")\n",
    "    \n",
    "    results = get_job_results(job_id, api_base_url=API_BASE_URL)\n",
    "    \n",
    "    # Extract step scores data\n",
    "    sequence_attr = results[\"sequence_attributions\"][0]\n",
    "    target_tokens = [token[\"token\"] for token in sequence_attr[\"target\"]]\n",
    "    \n",
    "    # Create a dataframe for step scores\n",
    "    step_scores_data = {}\n",
    "    for score_name, scores in sequence_attr[\"step_scores\"].items():\n",
    "        step_scores_data[score_name] = scores\n",
    "    \n",
    "    df_scores = pd.DataFrame(step_scores_data, index=target_tokens)\n",
    "    \n",
    "    # Basic analysis of step scores\n",
    "    print(\"\\nBasic statistics for each step score:\")\n",
    "    display(df_scores.describe())\n",
    "    \n",
    "    # Find tokens with highest/lowest scores\n",
    "    print(\"\\nTokens with extreme values:\")\n",
    "    for column in df_scores.columns:\n",
    "        max_token = df_scores[column].idxmax()\n",
    "        min_token = df_scores[column].idxmin()\n",
    "        print(f\"{column}: Highest = '{max_token}' ({df_scores[column].max():.4f}), Lowest = '{min_token}' ({df_scores[column].min():.4f})\")\n",
    "    \n",
    "    # Plot correlation matrix of step scores\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df_scores.corr(), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "    plt.title(\"Correlation Between Step Scores\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot step scores\n",
    "    plot_step_scores(results)\n",
    "    plot_multiple_step_scores(df_scores)\n",
    "    \n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"df_scores\": df_scores,\n",
    "        \"df_attribution\": create_attribution_dataframe(results)\n",
    "    }\n",
    "\n",
    "# Run the step scores analysis\n",
    "step_scores_analysis = analyze_step_scores()"
   ],
   "outputs": [],
   "id": "3d1d926b298b74f5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Model Compatibility\n",
    "\n",
    "Some models may require special handling. Here are some common issues and solutions:"
   ],
   "id": "90ce3fd4b3a3af9b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading Issues\n",
    "\n",
    "The API has been enhanced to handle various model loading scenarios, including:\n",
    "\n",
    "1. **Flax Models**: Some models have Flax weights instead of PyTorch weights. The API will automatically try loading with `from_flax=True` if it detects this case.\n",
    "\n",
    "2. **GPT-2 Variants**: Some GPT-2 models might require special handling. The API includes an alternative loading path for GPT-2 models.\n",
    "\n",
    "3. **Resource Constraints**: If you're getting memory errors, try these options:\n",
    "   - Use smaller models like 'distilgpt2' instead of larger ones\n",
    "   - Set `force_cpu=True` in your request\n",
    "   - Use simpler attribution methods like 'input_x_gradient' or 'saliency'"
   ],
   "id": "4fed5e4ef2edbcef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def test_model_compatibility(model=\"distilgpt2\"):\n",
    "    \"\"\"Test if a model works with the API.\"\"\"\n",
    "    print(f\"Testing compatibility with model: {model}\")\n",
    "    \n",
    "    try:\n",
    "        job_id = submit_attribution_job(\n",
    "            input_text=\"This is a test of model compatibility.\",\n",
    "            model=model,\n",
    "            method=\"input_x_gradient\",  # Use a simple method for testing\n",
    "            step_scores=[\"probability\"],\n",
    "            force_cpu=True,  # More reliable for testing\n",
    "            api_base_url=API_BASE_URL\n",
    "        )\n",
    "        \n",
    "        print(f\"Job submitted with ID: {job_id}\")\n",
    "        job_status = wait_for_job_completion(job_id, api_base_url=API_BASE_URL)\n",
    "        print(f\"Job completed with status: {job_status['status']}\")\n",
    "        \n",
    "        if job_status['status'] == 'completed':\n",
    "            print(f\"✅ Model '{model}' is compatible with the API.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Model '{model}' is not compatible with the API.\")\n",
    "            print(f\"Error: {job_status.get('error', 'Unknown error')}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error testing model '{model}': {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Uncomment to test a specific model\n",
    "# is_compatible = test_model_compatibility(\"distilgpt2\")"
   ],
   "outputs": [],
   "id": "e07bfcb1ad0e84b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Visualizations for Reports or Presentations\n",
    "\n",
    "This section shows how to create high-quality visualizations for including in reports or presentations."
   ],
   "id": "6b8f2796b6e87bd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_report_visualizations(results_dict, output_prefix=\"report_viz\"):\n",
    "    \"\"\"Create high-quality visualizations for reports from attribution results.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from matplotlib.colors import TwoSlopeNorm\n",
    "    \n",
    "    if not results_dict or 'df_attribution' not in results_dict:\n",
    "        print(\"No valid results provided. Please run an attribution example first.\")\n",
    "        return\n",
    "    \n",
    "    df_attribution = results_dict['df_attribution']\n",
    "    \n",
    "    # 1. Create a high-quality attribution heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create a custom colormap with white at zero\n",
    "    vmax = max(abs(df_attribution.values.min()), abs(df_attribution.values.max()))\n",
    "    norm = TwoSlopeNorm(vmin=-vmax, vcenter=0, vmax=vmax)\n",
    "    \n",
    "    ax = sns.heatmap(df_attribution, cmap=\"coolwarm\", center=0, annot=True, fmt=\".2f\", \n",
    "                linewidths=.5, xticklabels=True, yticklabels=True, norm=norm)\n",
    "    \n",
    "    plt.title(\"Feature Attribution: Source Tokens (Y) → Target Tokens (X)\", fontsize=16)\n",
    "    plt.xlabel(\"Generated Tokens\", fontsize=14)\n",
    "    plt.ylabel(\"Input Tokens\", fontsize=14)\n",
    "    \n",
    "    # Rotate x labels for better readability\n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_prefix}_heatmap.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Create a step scores visualization if available\n",
    "    if 'df_step_scores' in results_dict and results_dict['df_step_scores'] is not None:\n",
    "        df_scores = results_dict['df_step_scores']\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for column in df_scores.columns:\n",
    "            plt.plot(df_scores.index, df_scores[column], marker='o', linewidth=2, markersize=8, label=column)\n",
    "        \n",
    "        plt.xlabel(\"Generated Tokens\", fontsize=14)\n",
    "        plt.ylabel(\"Score\", fontsize=14)\n",
    "        plt.title(\"Step Scores by Token\", fontsize=16)\n",
    "        plt.xticks(rotation=45, ha=\"right\", fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_prefix}_step_scores.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. Create a bar chart of important tokens\n",
    "    df_important = find_important_tokens(df_attribution)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.bar(df_important['target_token'], df_important['score'], color=[(0, 0.5, 0.8) if x > 0 else (0.8, 0.2, 0.2) for x in df_important['score']])\n",
    "    \n",
    "    plt.xlabel(\"Generated Token\", fontsize=14)\n",
    "    plt.ylabel(\"Attribution Score of Most Important Input Token\", fontsize=14)\n",
    "    plt.title(\"Most Important Input Token for Each Generated Token\", fontsize=16)\n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    # Add the source token labels above the bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        source_token = df_important.iloc[i]['source_token']\n",
    "        score = df_important.iloc[i]['score']\n",
    "        y_pos = score + 0.02*max(abs(df_important['score'])) if score > 0 else score - 0.08*max(abs(df_important['score']))\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, y_pos, \n",
    "                 f\"'{source_token}'\", ha='center', va='bottom', fontsize=10, rotation=45)\n",
    "    \n",
    "    plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_prefix}_important_tokens.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Visualization files saved with prefix: {output_prefix}\")\n",
    "\n",
    "# Create report visualizations if you've run an attribution example\n",
    "# Uncomment to create report visualizations\n",
    "# if 'simple_results' in locals():\n",
    "#     create_report_visualizations(simple_results)"
   ],
   "outputs": [],
   "id": "6ec7e8ce92de5050"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
